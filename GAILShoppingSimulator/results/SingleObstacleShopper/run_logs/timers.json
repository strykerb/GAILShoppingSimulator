{
    "name": "root",
    "gauges": {
        "Shopping.Policy.Entropy.mean": {
            "value": 1.158873200416565,
            "min": 1.1094369888305664,
            "max": 1.8966479301452637,
            "count": 5
        },
        "Shopping.Policy.Entropy.sum": {
            "value": 11611.9091796875,
            "min": 10983.42578125,
            "max": 19725.138671875,
            "count": 5
        },
        "Shopping.Environment.EpisodeLength.mean": {
            "value": 390.0,
            "min": 16.18683274021352,
            "max": 390.0,
            "count": 5
        },
        "Shopping.Environment.EpisodeLength.sum": {
            "value": 2730.0,
            "min": 2730.0,
            "max": 9097.0,
            "count": 5
        },
        "Shopping.Step.mean": {
            "value": 49955.0,
            "min": 9979.0,
            "max": 49955.0,
            "count": 5
        },
        "Shopping.Step.sum": {
            "value": 49955.0,
            "min": 9979.0,
            "max": 49955.0,
            "count": 5
        },
        "Shopping.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.08729076385498047,
            "min": -0.8156840205192566,
            "max": -0.08729076385498047,
            "count": 5
        },
        "Shopping.Policy.ExtrinsicValueEstimate.sum": {
            "value": -13.966522216796875,
            "min": -484.51629638671875,
            "max": -13.966522216796875,
            "count": 5
        },
        "Shopping.Environment.CumulativeReward.mean": {
            "value": -0.7142857142857143,
            "min": -0.9644128113879004,
            "max": -0.7142857142857143,
            "count": 5
        },
        "Shopping.Environment.CumulativeReward.sum": {
            "value": -5.0,
            "min": -542.0,
            "max": -5.0,
            "count": 5
        },
        "Shopping.Policy.ExtrinsicReward.mean": {
            "value": -0.7142857142857143,
            "min": -0.9644128113879004,
            "max": -0.7142857142857143,
            "count": 5
        },
        "Shopping.Policy.ExtrinsicReward.sum": {
            "value": -5.0,
            "min": -542.0,
            "max": -5.0,
            "count": 5
        },
        "Shopping.Losses.PolicyLoss.mean": {
            "value": 0.24819843185762414,
            "min": 0.24304682118274046,
            "max": 0.24819843185762414,
            "count": 5
        },
        "Shopping.Losses.PolicyLoss.sum": {
            "value": 18.863080821179434,
            "min": 17.64543527143989,
            "max": 20.01567215664791,
            "count": 5
        },
        "Shopping.Losses.ValueLoss.mean": {
            "value": 0.005760325127840506,
            "min": 0.005760325127840506,
            "max": 0.05235037969971188,
            "count": 5
        },
        "Shopping.Losses.ValueLoss.sum": {
            "value": 0.4377847097158784,
            "min": 0.4377847097158784,
            "max": 3.978628857178103,
            "count": 5
        },
        "Shopping.Policy.LearningRate.mean": {
            "value": 0.000273085098445321,
            "min": 0.000273085098445321,
            "max": 0.0002970440570828756,
            "count": 5
        },
        "Shopping.Policy.LearningRate.sum": {
            "value": 0.020754467481844396,
            "min": 0.020090059103313795,
            "max": 0.0243576126807958,
            "count": 5
        },
        "Shopping.Policy.Epsilon.mean": {
            "value": 0.19102836315789473,
            "min": 0.19102836315789473,
            "max": 0.19901468536585368,
            "count": 5
        },
        "Shopping.Policy.Epsilon.sum": {
            "value": 14.5181556,
            "min": 13.896686200000001,
            "max": 16.3192042,
            "count": 5
        },
        "Shopping.Policy.Beta.mean": {
            "value": 0.00045603897947368426,
            "min": 0.00045603897947368426,
            "max": 0.0004951719582926829,
            "count": 5
        },
        "Shopping.Policy.Beta.sum": {
            "value": 0.03465896244,
            "min": 0.03353376238,
            "max": 0.04060410058,
            "count": 5
        },
        "Shopping.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 5
        },
        "Shopping.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 5
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1629753215",
        "python_version": "3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\stryk\\Desktop\\iSTAR\\ML-Agents\\venv\\Scripts\\mlagents-learn config\\shopper.yaml --run-id=SingleObstacleShopper",
        "mlagents_version": "0.27.0",
        "mlagents_envs_version": "0.27.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.0+cu110",
        "numpy_version": "1.21.1",
        "end_time_seconds": "1629753366"
    },
    "total": 151.1463312,
    "count": 1,
    "self": 0.0046681000000035056,
    "children": {
        "run_training.setup": {
            "total": 0.07044470000000003,
            "count": 1,
            "self": 0.07044470000000003
        },
        "TrainerController.start_learning": {
            "total": 151.0712184,
            "count": 1,
            "self": 0.06767389999950524,
            "children": {
                "TrainerController._reset_env": {
                    "total": 6.0813827,
                    "count": 1,
                    "self": 6.0813827
                },
                "TrainerController.advance": {
                    "total": 144.83472150000046,
                    "count": 3588,
                    "self": 0.06632029999997258,
                    "children": {
                        "env_step": {
                            "total": 43.054534400000676,
                            "count": 3588,
                            "self": 37.24048330000128,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 5.7756496999999065,
                                    "count": 3588,
                                    "self": 0.15010419999994884,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 5.625545499999958,
                                            "count": 2864,
                                            "self": 2.3630066999998984,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 3.2625388000000592,
                                                    "count": 2864,
                                                    "self": 3.2625388000000592
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.03840139999949255,
                                    "count": 3587,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 145.45346539999997,
                                            "count": 3587,
                                            "is_parallel": true,
                                            "self": 112.22414559999982,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0009223999999994348,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00024139999999928108,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0006810000000001537,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.0006810000000001537
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 33.22839740000015,
                                                    "count": 3587,
                                                    "is_parallel": true,
                                                    "self": 0.7327853000002236,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 0.6374084999996912,
                                                            "count": 3587,
                                                            "is_parallel": true,
                                                            "self": 0.6374084999996912
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 29.50670210000017,
                                                            "count": 3587,
                                                            "is_parallel": true,
                                                            "self": 29.50670210000017
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 2.351501500000068,
                                                            "count": 3587,
                                                            "is_parallel": true,
                                                            "self": 0.6268490000005702,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 1.7246524999994977,
                                                                    "count": 14348,
                                                                    "is_parallel": true,
                                                                    "self": 1.7246524999994977
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 101.7138667999998,
                            "count": 3587,
                            "self": 0.12575799999994786,
                            "children": {
                                "process_trajectory": {
                                    "total": 5.028859599999854,
                                    "count": 3587,
                                    "self": 5.028859599999854
                                },
                                "_update_policy": {
                                    "total": 96.55924920000001,
                                    "count": 425,
                                    "self": 7.802266899999836,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 88.75698230000017,
                                            "count": 16296,
                                            "self": 88.75698230000017
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.1000000199601345e-06,
                    "count": 1,
                    "self": 1.1000000199601345e-06
                },
                "TrainerController._save_models": {
                    "total": 0.08743920000000571,
                    "count": 1,
                    "self": 0.007659300000000258,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.07977990000000545,
                            "count": 1,
                            "self": 0.07977990000000545
                        }
                    }
                }
            }
        }
    }
}